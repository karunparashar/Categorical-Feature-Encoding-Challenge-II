{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 binary,10 nominal,6 ordinal\n",
    "#null values\n",
    "col_names= list(df.columns)\n",
    "col_names\n",
    "em=[]\n",
    "nd = {}\n",
    "# df.iloc[:,1]\n",
    "for i in col_names:\n",
    "    if sum(df[i].isnull())>0:\n",
    "        nd[i] = sum(df[i].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#unique values\n",
    "ne ={}\n",
    "for i in col_names:\n",
    "    if sum(df[i].isnull())>0:\n",
    "        ne[i] = len(df[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#redundant columns to remove \n",
    "columns_to_use= list(df.columns)\n",
    "col2remove= [\"nom_5\",\"nom_6\",\"nom_7\",\"nom_8\",\"nom_9\",\"ord_5\"]\n",
    "cols =[]\n",
    "for i in columns_to_use:\n",
    "    if i not in col2remove:\n",
    "        cols.append(i)\n",
    "df2 = pd.DataFrame()\n",
    "for i in cols:\n",
    "    df2[i] = df[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing NA with the most frequent value in that column\n",
    "import statistics\n",
    "df2.bin_0.fillna(statistics.mode(df2.bin_0),inplace=True)\n",
    "for i in cols:\n",
    "    if sum(df2[i].isnull())!=0:\n",
    "        df2[i].fillna(statistics.mode(df2[i]),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy = df2.copy(deep=True)\n",
    "dummy = pd.get_dummies(df_dummy['nom_0'],prefix = \"nom_0\")\n",
    "df_dummy = df_dummy.merge(dummy,left_index=True,right_index=True)\n",
    "df_dummy = df_dummy.drop(['nom_0'],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_dummy.columns\n",
    "\n",
    "df_x_d = df_dummy.iloc[:,0:86]\n",
    "df_y_d = df_dummy.iloc[:,86]\n",
    "\n",
    "x_train_d, x_test_d, y_train_d, y_test_d = train_test_split(df_x_d,df_y_d,\n",
    "                                                    train_size=0.8,test_size=0.2,\n",
    "                                                    random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding\n",
    "cols2 = ['nom_0',\n",
    "         'nom_1',\n",
    "         'nom_2',\n",
    "         'nom_3',\n",
    "         'nom_4',\n",
    "         'ord_1',\n",
    "         'ord_2',\n",
    "         'ord_3',\n",
    "         'ord_4',]\n",
    "for i in cols2:\n",
    "    dummy = pd.get_dummies(df_dummy[i],prefix = f\"{i}\")\n",
    "    df_dummy = df_dummy.merge(dummy,left_index=True,right_index=True)\n",
    "    df_dummy = df_dummy.drop([i],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reindexing to make sure the target column remains in the last\n",
    "df2.ord_2.unique()\n",
    "columns_titles = ['id', 'bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4', 'ord_0', 'day',\n",
    "       'month', 'nom_0_Blue', 'nom_0_Green', 'nom_0_Red',\n",
    "       'nom_1_Circle', 'nom_1_Polygon', 'nom_1_Square', 'nom_1_Star',\n",
    "       'nom_1_Trapezoid', 'nom_1_Triangle', 'nom_2_Axolotl', 'nom_2_Cat',\n",
    "       'nom_2_Dog', 'nom_2_Hamster', 'nom_2_Lion', 'nom_2_Snake',\n",
    "       'nom_3_Canada', 'nom_3_China', 'nom_3_Costa Rica', 'nom_3_Finland',\n",
    "       'nom_3_India', 'nom_3_Russia', 'nom_4_Bassoon', 'nom_4_Oboe',\n",
    "       'nom_4_Piano', 'nom_4_Theremin', 'ord_1_Contributor', 'ord_1_Expert',\n",
    "       'ord_1_Grandmaster', 'ord_1_Master', 'ord_1_Novice',\n",
    "       'ord_2_Boiling Hot', 'ord_2_Cold', 'ord_2_Freezing', 'ord_2_Hot',\n",
    "       'ord_2_Lava Hot', 'ord_2_Warm', 'ord_3_a', 'ord_3_b', 'ord_3_c',\n",
    "       'ord_3_d', 'ord_3_e', 'ord_3_f', 'ord_3_g', 'ord_3_h', 'ord_3_i',\n",
    "       'ord_3_j', 'ord_3_k', 'ord_3_l', 'ord_3_m', 'ord_3_n', 'ord_3_o',\n",
    "       'ord_4_A', 'ord_4_B', 'ord_4_C', 'ord_4_D', 'ord_4_E', 'ord_4_F',\n",
    "       'ord_4_G', 'ord_4_H', 'ord_4_I', 'ord_4_J', 'ord_4_K', 'ord_4_L',\n",
    "       'ord_4_M', 'ord_4_N', 'ord_4_O', 'ord_4_P', 'ord_4_Q', 'ord_4_R',\n",
    "       'ord_4_S', 'ord_4_T', 'ord_4_U', 'ord_4_V', 'ord_4_W', 'ord_4_X',\n",
    "       'ord_4_Y', 'ord_4_Z','target']\n",
    "df_dummy=df_dummy.reindex(columns=columns_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will perform oversampling using SMOTE\n",
    "# import imblearn\n",
    "from imblearn.over_sampling import SMOTE \n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(df_x_d,df_dummy.iloc[:,86])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient boosting without oversampling-default parameters-81.53\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc_model = gbc.fit(x_train_d,y_train_d)\n",
    "pred_gb = gbc_model.predict(x_test_d)\n",
    "accuracy_score(y_test_d, pred_gb, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient boosting without oversampling-tuned parameters-81.71\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc_hyper = GradientBoostingClassifier(min_samples_split=500,min_samples_leaf=250,\n",
    "                                max_features=24,learning_rate=0.2,subsample=0.8,\n",
    "                                n_estimators=500,verbose=1,presort=True)\n",
    "gbc_model_hyper = gbc_hyper.fit(x_train_d,y_train_d)\n",
    "pred_gb_hyper = gbc_model_hyper.predict(x_test_d)\n",
    "accuracy_score(y_test_d, pred_gb_hyper, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient boosting with oversampling-default parameters-81.47\n",
    "x_s,y_s = sm.fit_resample(x_train_d,y_train_d)\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc_over = GradientBoostingClassifier()\n",
    "gbc_model_over = gbc_over.fit(x_s,y_s)\n",
    "pred_gb_over = gbc_model_over.predict(x_test_d)\n",
    "accuracy_score(y_test_d, pred_gb_over, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient boosting with oversampling-tuning parameters-81.7\n",
    "# x_s,y_s = sm.fit_resample(x_train_d,y_train_d)\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc_over_hyper = GradientBoostingClassifier(min_samples_split=500,min_samples_leaf=250,\n",
    "                                max_features=24,learning_rate=0.2,subsample=0.8,\n",
    "                                n_estimators=500,verbose=1,presort=True)\n",
    "gbc_model_over_hyper = gbc_over_hyper.fit(x_s,y_s)\n",
    "pred_gb_over_hyper = gbc_model_over_hyper.predict(x_test_d)\n",
    "accuracy_score(y_test_d, pred_gb_over_hyper, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear model prediction accuracy using full feature set-81.47\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm_model = lm.fit(df_x_d,df_y_d)\n",
    "# pred_lm = lm_model.predict(x_test_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lm[pred_lm>0.5]=1\n",
    "pred_lm[pred_lm<0.5]=0\n",
    "pred_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test_d, pred_lm, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference-feature selection using Recursive feature elimination reduces the accuracy by a fraction\n",
    "from sklearn.feature_selection import RFE\n",
    "rfe_ml = RFE(lm,20)\n",
    "#transforming training data to RFE format\n",
    "X_rfe = rfe_ml.fit_transform(x_train_d,y_train_d)  \n",
    "#test data transformation\n",
    "X_rfe_test = rfe_ml.fit_transform(x_test_d,y_test_d)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction using reduced feature set\n",
    "rfe_model = lm_model.fit(X_rfe,y_train_d)\n",
    "pred_lm_rfe = rfe_model.predict(X_rfe_test)\n",
    "# X_rfe.shape\n",
    "pred_lm_rfe[pred_lm_rfe>0.5]=1\n",
    "pred_lm_rfe[pred_lm_rfe<0.5]=0\n",
    "accuracy_score(y_test_d, pred_lm_rfe, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic model accuracy with full feature set-81.294\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "Log_reg = LogisticRegression(penalty='l2', dual=False, tol=0.0001)\n",
    "log_model = Log_reg.fit(df_x_d,df_y_d)\n",
    "# pred_log = log_model.predict(x_test_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test_d, pred_log, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming data into 20 best features for logistic regression\n",
    "rfe_log = RFE(Log_reg,20)\n",
    "X_rfe_train_log = rfe_log.fit_transform(x_train_d,y_train_d)\n",
    "X_rfe_test_log = rfe_log.fit_transform(x_test_d,y_test_d)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic reg prediction using reduced feature set-no change in accuracy\n",
    "rfe_model_log = rfe_log.fit(X_rfe_train_log,y_train_d)\n",
    "pred_log_rfe = rfe_model_log.predict(X_rfe_test_log)\n",
    "accuracy_score(y_test_d, pred_log_rfe, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perceptron classification accuracy same as Logistic-81.294\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=10, activation='relu', solver='adam', alpha=0.0001)\n",
    "mlp_model = mlp.fit(x_train_d,y_train_d)\n",
    "pred_mlp = mlp_model.predict(x_test_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test_d, pred_mlp, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest model prediction accuracy using full feature set-81.44\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_m = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto')\n",
    "rf_model = rf_m.fit(df_x_d,df_y_d)\n",
    "# pred_rf = rf_model.predict(x_test_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
